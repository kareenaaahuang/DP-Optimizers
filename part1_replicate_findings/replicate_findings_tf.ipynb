{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Dense, Dropout, GaussianNoise, Conv1D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data import and clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in mnist dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# normalize data\n",
    "x_train = x_train/255\n",
    "x_test = x_test/255\n",
    "\n",
    "# get flat datasets for non-conv tasks\n",
    "x_train_flat = x_train.reshape(60000, 28*28)\n",
    "x_test_flat = x_test.reshape(10000, 28*28)\n",
    "\n",
    "# one hot encode targets\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes=None, dtype='float32')\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes=None, dtype='float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lot_size = 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PCA LAYER\n",
    "n_components = 60\n",
    "\n",
    "pca = PCA(n_components=n_components)\n",
    "x_pca_train = pca.fit_transform(x_train_flat)\n",
    "x_pca_test = pca.transform(x_test_flat)\n",
    "pca_std = np.std(x_pca_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/envs/208proj/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# Neural Net building on PCA\n",
    "model = Sequential()\n",
    "layers = 1\n",
    "units = 1000\n",
    "\n",
    "model.add(Dense(units, input_dim=n_components, activation='relu'))\n",
    "model.add(Dense(10, activation = 'softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 1000)              61000     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                10010     \n",
      "=================================================================\n",
      "Total params: 71,010\n",
      "Trainable params: 71,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/envs/208proj/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 0.4957 - categorical_accuracy: 0.8911 - val_loss: 0.2079 - val_categorical_accuracy: 0.9419\n",
      "Epoch 2/100\n",
      " - 0s - loss: 0.1725 - categorical_accuracy: 0.9511 - val_loss: 0.1379 - val_categorical_accuracy: 0.9622\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.1170 - categorical_accuracy: 0.9674 - val_loss: 0.1105 - val_categorical_accuracy: 0.9691\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.0874 - categorical_accuracy: 0.9766 - val_loss: 0.0922 - val_categorical_accuracy: 0.9744\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.0685 - categorical_accuracy: 0.9819 - val_loss: 0.0815 - val_categorical_accuracy: 0.9778\n",
      "Epoch 6/100\n",
      " - 0s - loss: 0.0556 - categorical_accuracy: 0.9850 - val_loss: 0.0762 - val_categorical_accuracy: 0.9781\n",
      "Epoch 7/100\n",
      " - 0s - loss: 0.0457 - categorical_accuracy: 0.9883 - val_loss: 0.0707 - val_categorical_accuracy: 0.9804\n",
      "Epoch 8/100\n",
      " - 0s - loss: 0.0381 - categorical_accuracy: 0.9904 - val_loss: 0.0672 - val_categorical_accuracy: 0.9801\n",
      "Epoch 9/100\n",
      " - 0s - loss: 0.0322 - categorical_accuracy: 0.9924 - val_loss: 0.0632 - val_categorical_accuracy: 0.9817\n",
      "Epoch 10/100\n",
      " - 0s - loss: 0.0271 - categorical_accuracy: 0.9939 - val_loss: 0.0624 - val_categorical_accuracy: 0.9823\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.0226 - categorical_accuracy: 0.9954 - val_loss: 0.0624 - val_categorical_accuracy: 0.9819\n",
      "Epoch 12/100\n",
      " - 0s - loss: 0.0191 - categorical_accuracy: 0.9964 - val_loss: 0.0628 - val_categorical_accuracy: 0.9818\n",
      "Epoch 13/100\n",
      " - 0s - loss: 0.0162 - categorical_accuracy: 0.9971 - val_loss: 0.0645 - val_categorical_accuracy: 0.9808\n",
      "Epoch 14/100\n",
      " - 0s - loss: 0.0132 - categorical_accuracy: 0.9979 - val_loss: 0.0610 - val_categorical_accuracy: 0.9830\n",
      "Epoch 15/100\n",
      " - 0s - loss: 0.0111 - categorical_accuracy: 0.9982 - val_loss: 0.0607 - val_categorical_accuracy: 0.9834\n",
      "Epoch 16/100\n",
      " - 1s - loss: 0.0094 - categorical_accuracy: 0.9987 - val_loss: 0.0607 - val_categorical_accuracy: 0.9834\n",
      "Epoch 17/100\n",
      " - 1s - loss: 0.0078 - categorical_accuracy: 0.9991 - val_loss: 0.0613 - val_categorical_accuracy: 0.9824\n",
      "Epoch 18/100\n",
      " - 0s - loss: 0.0062 - categorical_accuracy: 0.9993 - val_loss: 0.0611 - val_categorical_accuracy: 0.9834\n",
      "Epoch 19/100\n",
      " - 0s - loss: 0.0053 - categorical_accuracy: 0.9994 - val_loss: 0.0639 - val_categorical_accuracy: 0.9824\n",
      "Epoch 20/100\n",
      " - 0s - loss: 0.0044 - categorical_accuracy: 0.9997 - val_loss: 0.0645 - val_categorical_accuracy: 0.9832\n",
      "Epoch 21/100\n",
      " - 0s - loss: 0.0036 - categorical_accuracy: 0.9998 - val_loss: 0.0653 - val_categorical_accuracy: 0.9833\n",
      "Epoch 22/100\n",
      " - 0s - loss: 0.0030 - categorical_accuracy: 0.9998 - val_loss: 0.0669 - val_categorical_accuracy: 0.9828\n",
      "Epoch 23/100\n",
      " - 0s - loss: 0.0025 - categorical_accuracy: 0.9999 - val_loss: 0.0657 - val_categorical_accuracy: 0.9834\n",
      "Epoch 24/100\n",
      " - 0s - loss: 0.0019 - categorical_accuracy: 0.9999 - val_loss: 0.0695 - val_categorical_accuracy: 0.9829\n",
      "Epoch 25/100\n",
      " - 0s - loss: 0.0018 - categorical_accuracy: 0.9999 - val_loss: 0.0683 - val_categorical_accuracy: 0.9835\n",
      "Epoch 26/100\n",
      " - 0s - loss: 0.0015 - categorical_accuracy: 0.9999 - val_loss: 0.0697 - val_categorical_accuracy: 0.9832\n",
      "Epoch 27/100\n",
      " - 0s - loss: 0.0011 - categorical_accuracy: 1.0000 - val_loss: 0.0709 - val_categorical_accuracy: 0.9838\n",
      "Epoch 28/100\n",
      " - 0s - loss: 9.5280e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0741 - val_categorical_accuracy: 0.9828\n",
      "Epoch 29/100\n",
      " - 0s - loss: 8.0815e-04 - categorical_accuracy: 0.9999 - val_loss: 0.0731 - val_categorical_accuracy: 0.9839\n",
      "Epoch 30/100\n",
      " - 0s - loss: 6.8525e-04 - categorical_accuracy: 0.9999 - val_loss: 0.0731 - val_categorical_accuracy: 0.9840\n",
      "Epoch 31/100\n",
      " - 0s - loss: 5.0440e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0750 - val_categorical_accuracy: 0.9838\n",
      "Epoch 32/100\n",
      " - 0s - loss: 4.6939e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0764 - val_categorical_accuracy: 0.9831\n",
      "Epoch 33/100\n",
      " - 0s - loss: 3.8231e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0777 - val_categorical_accuracy: 0.9832\n",
      "Epoch 34/100\n",
      " - 0s - loss: 3.0167e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0797 - val_categorical_accuracy: 0.9837\n",
      "Epoch 35/100\n",
      " - 0s - loss: 2.7877e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0825 - val_categorical_accuracy: 0.9832\n",
      "Epoch 36/100\n",
      " - 0s - loss: 1.8873e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0809 - val_categorical_accuracy: 0.9838\n",
      "Epoch 37/100\n",
      " - 0s - loss: 1.8005e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0829 - val_categorical_accuracy: 0.9840\n",
      "Epoch 38/100\n",
      " - 0s - loss: 1.3093e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0852 - val_categorical_accuracy: 0.9840\n",
      "Epoch 39/100\n",
      " - 0s - loss: 1.2243e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0850 - val_categorical_accuracy: 0.9831\n",
      "Epoch 40/100\n",
      " - 0s - loss: 1.1480e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0890 - val_categorical_accuracy: 0.9832\n",
      "Epoch 41/100\n",
      " - 0s - loss: 8.1973e-05 - categorical_accuracy: 1.0000 - val_loss: 0.0875 - val_categorical_accuracy: 0.9841\n",
      "Epoch 42/100\n",
      " - 0s - loss: 5.5546e-05 - categorical_accuracy: 1.0000 - val_loss: 0.0910 - val_categorical_accuracy: 0.9833\n",
      "Epoch 43/100\n",
      " - 0s - loss: 4.8901e-05 - categorical_accuracy: 1.0000 - val_loss: 0.0925 - val_categorical_accuracy: 0.9838\n",
      "Epoch 44/100\n",
      " - 0s - loss: 4.3503e-05 - categorical_accuracy: 1.0000 - val_loss: 0.0929 - val_categorical_accuracy: 0.9834\n",
      "Epoch 45/100\n",
      " - 0s - loss: 3.1267e-05 - categorical_accuracy: 1.0000 - val_loss: 0.0934 - val_categorical_accuracy: 0.9826\n",
      "Epoch 46/100\n",
      " - 0s - loss: 2.8135e-05 - categorical_accuracy: 1.0000 - val_loss: 0.0953 - val_categorical_accuracy: 0.9836\n",
      "Epoch 47/100\n",
      " - 0s - loss: 4.7452e-05 - categorical_accuracy: 1.0000 - val_loss: 0.0961 - val_categorical_accuracy: 0.9838\n",
      "Epoch 48/100\n",
      " - 0s - loss: 1.3935e-05 - categorical_accuracy: 1.0000 - val_loss: 0.1008 - val_categorical_accuracy: 0.9834\n",
      "Epoch 49/100\n",
      " - 0s - loss: 2.0593e-05 - categorical_accuracy: 1.0000 - val_loss: 0.1002 - val_categorical_accuracy: 0.9830\n",
      "Epoch 50/100\n",
      " - 0s - loss: 2.2917e-05 - categorical_accuracy: 1.0000 - val_loss: 0.1024 - val_categorical_accuracy: 0.9831\n",
      "Epoch 51/100\n",
      " - 0s - loss: 1.8463e-05 - categorical_accuracy: 1.0000 - val_loss: 0.1001 - val_categorical_accuracy: 0.9841\n",
      "Epoch 52/100\n",
      " - 0s - loss: 9.9216e-06 - categorical_accuracy: 1.0000 - val_loss: 0.1017 - val_categorical_accuracy: 0.9828\n",
      "Epoch 53/100\n",
      " - 0s - loss: 6.7403e-06 - categorical_accuracy: 1.0000 - val_loss: 0.1046 - val_categorical_accuracy: 0.9833\n",
      "Epoch 54/100\n",
      " - 0s - loss: 6.3647e-06 - categorical_accuracy: 1.0000 - val_loss: 0.1040 - val_categorical_accuracy: 0.9836\n",
      "Epoch 55/100\n",
      " - 0s - loss: 4.0481e-06 - categorical_accuracy: 1.0000 - val_loss: 0.1045 - val_categorical_accuracy: 0.9836\n",
      "Epoch 56/100\n",
      " - 0s - loss: 6.6032e-06 - categorical_accuracy: 1.0000 - val_loss: 0.1057 - val_categorical_accuracy: 0.9831\n",
      "Epoch 57/100\n",
      " - 0s - loss: 2.7961e-06 - categorical_accuracy: 1.0000 - val_loss: 0.1069 - val_categorical_accuracy: 0.9829\n",
      "Epoch 58/100\n",
      " - 0s - loss: 2.8636e-06 - categorical_accuracy: 1.0000 - val_loss: 0.1077 - val_categorical_accuracy: 0.9830\n",
      "Epoch 59/100\n",
      " - 0s - loss: 1.1202e-05 - categorical_accuracy: 1.0000 - val_loss: 0.1064 - val_categorical_accuracy: 0.9835\n",
      "Epoch 60/100\n",
      " - 0s - loss: 1.4865e-06 - categorical_accuracy: 1.0000 - val_loss: 0.1073 - val_categorical_accuracy: 0.9833\n",
      "Epoch 61/100\n",
      " - 0s - loss: 1.3424e-06 - categorical_accuracy: 1.0000 - val_loss: 0.1073 - val_categorical_accuracy: 0.9838\n",
      "Epoch 62/100\n",
      " - 0s - loss: 1.1262e-06 - categorical_accuracy: 1.0000 - val_loss: 0.1089 - val_categorical_accuracy: 0.9834\n",
      "Epoch 63/100\n",
      " - 0s - loss: 9.1932e-07 - categorical_accuracy: 1.0000 - val_loss: 0.1095 - val_categorical_accuracy: 0.9835\n",
      "Epoch 64/100\n",
      " - 0s - loss: 8.6366e-07 - categorical_accuracy: 1.0000 - val_loss: 0.1105 - val_categorical_accuracy: 0.9829\n",
      "Epoch 65/100\n",
      " - 0s - loss: 7.2154e-07 - categorical_accuracy: 1.0000 - val_loss: 0.1108 - val_categorical_accuracy: 0.9835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/100\n",
      " - 0s - loss: 6.6062e-07 - categorical_accuracy: 1.0000 - val_loss: 0.1111 - val_categorical_accuracy: 0.9837\n",
      "Epoch 67/100\n",
      " - 0s - loss: 6.1164e-07 - categorical_accuracy: 1.0000 - val_loss: 0.1108 - val_categorical_accuracy: 0.9838\n",
      "Epoch 68/100\n",
      " - 0s - loss: 5.1504e-07 - categorical_accuracy: 1.0000 - val_loss: 0.1119 - val_categorical_accuracy: 0.9831\n",
      "Epoch 69/100\n",
      " - 0s - loss: 4.9787e-07 - categorical_accuracy: 1.0000 - val_loss: 0.1120 - val_categorical_accuracy: 0.9831\n",
      "Epoch 70/100\n",
      " - 0s - loss: 4.5290e-07 - categorical_accuracy: 1.0000 - val_loss: 0.1124 - val_categorical_accuracy: 0.9833\n",
      "Epoch 71/100\n",
      " - 0s - loss: 4.1279e-07 - categorical_accuracy: 1.0000 - val_loss: 0.1122 - val_categorical_accuracy: 0.9833\n",
      "Epoch 72/100\n",
      " - 0s - loss: 3.9634e-07 - categorical_accuracy: 1.0000 - val_loss: 0.1133 - val_categorical_accuracy: 0.9833\n",
      "Epoch 73/100\n",
      " - 0s - loss: 3.7482e-07 - categorical_accuracy: 1.0000 - val_loss: 0.1137 - val_categorical_accuracy: 0.9831\n",
      "Epoch 74/100\n",
      " - 0s - loss: 3.5298e-07 - categorical_accuracy: 1.0000 - val_loss: 0.1135 - val_categorical_accuracy: 0.9834\n",
      "Epoch 75/100\n",
      " - 0s - loss: 3.3930e-07 - categorical_accuracy: 1.0000 - val_loss: 0.1135 - val_categorical_accuracy: 0.9839\n",
      "Epoch 76/100\n",
      " - 0s - loss: 3.2456e-07 - categorical_accuracy: 1.0000 - val_loss: 0.1140 - val_categorical_accuracy: 0.9835\n",
      "Epoch 77/100\n",
      " - 0s - loss: 3.1269e-07 - categorical_accuracy: 1.0000 - val_loss: 0.1148 - val_categorical_accuracy: 0.9833\n",
      "Epoch 78/100\n",
      " - 0s - loss: 3.0131e-07 - categorical_accuracy: 1.0000 - val_loss: 0.1147 - val_categorical_accuracy: 0.9833\n",
      "Epoch 79/100\n",
      " - 0s - loss: 2.9276e-07 - categorical_accuracy: 1.0000 - val_loss: 0.1149 - val_categorical_accuracy: 0.9832\n",
      "Epoch 80/100\n",
      " - 0s - loss: 2.8357e-07 - categorical_accuracy: 1.0000 - val_loss: 0.1151 - val_categorical_accuracy: 0.9836\n",
      "Epoch 81/100\n",
      " - 0s - loss: 2.7634e-07 - categorical_accuracy: 1.0000 - val_loss: 0.1153 - val_categorical_accuracy: 0.9834\n",
      "Epoch 82/100\n",
      " - 0s - loss: 2.6890e-07 - categorical_accuracy: 1.0000 - val_loss: 0.1152 - val_categorical_accuracy: 0.9833\n",
      "Epoch 83/100\n",
      " - 0s - loss: 2.6252e-07 - categorical_accuracy: 1.0000 - val_loss: 0.1157 - val_categorical_accuracy: 0.9833\n",
      "Epoch 84/100\n",
      " - 0s - loss: 2.5569e-07 - categorical_accuracy: 1.0000 - val_loss: 0.1157 - val_categorical_accuracy: 0.9833\n",
      "Epoch 85/100\n",
      " - 0s - loss: 2.5039e-07 - categorical_accuracy: 1.0000 - val_loss: 0.1157 - val_categorical_accuracy: 0.9833\n",
      "Epoch 86/100\n",
      " - 0s - loss: 2.4484e-07 - categorical_accuracy: 1.0000 - val_loss: 0.1157 - val_categorical_accuracy: 0.9833\n",
      "Epoch 87/100\n",
      " - 0s - loss: 2.3984e-07 - categorical_accuracy: 1.0000 - val_loss: 0.1162 - val_categorical_accuracy: 0.9830\n",
      "Epoch 88/100\n",
      " - 0s - loss: 2.3610e-07 - categorical_accuracy: 1.0000 - val_loss: 0.1162 - val_categorical_accuracy: 0.9832\n",
      "Epoch 89/100\n",
      " - 0s - loss: 2.3115e-07 - categorical_accuracy: 1.0000 - val_loss: 0.1160 - val_categorical_accuracy: 0.9835\n",
      "Epoch 90/100\n",
      " - 0s - loss: 2.2670e-07 - categorical_accuracy: 1.0000 - val_loss: 0.1166 - val_categorical_accuracy: 0.9838\n",
      "Epoch 91/100\n",
      " - 0s - loss: 2.2386e-07 - categorical_accuracy: 1.0000 - val_loss: 0.1166 - val_categorical_accuracy: 0.9837\n",
      "Epoch 92/100\n",
      " - 0s - loss: 2.2017e-07 - categorical_accuracy: 1.0000 - val_loss: 0.1167 - val_categorical_accuracy: 0.9834\n",
      "Epoch 93/100\n",
      " - 0s - loss: 2.1639e-07 - categorical_accuracy: 1.0000 - val_loss: 0.1168 - val_categorical_accuracy: 0.9832\n",
      "Epoch 94/100\n",
      " - 0s - loss: 2.1341e-07 - categorical_accuracy: 1.0000 - val_loss: 0.1170 - val_categorical_accuracy: 0.9833\n",
      "Epoch 95/100\n",
      " - 0s - loss: 2.1048e-07 - categorical_accuracy: 1.0000 - val_loss: 0.1170 - val_categorical_accuracy: 0.9833\n",
      "Epoch 96/100\n",
      " - 0s - loss: 2.0767e-07 - categorical_accuracy: 1.0000 - val_loss: 0.1172 - val_categorical_accuracy: 0.9834\n",
      "Epoch 97/100\n",
      " - 0s - loss: 2.0461e-07 - categorical_accuracy: 1.0000 - val_loss: 0.1171 - val_categorical_accuracy: 0.9836\n",
      "Epoch 98/100\n",
      " - 0s - loss: 2.0247e-07 - categorical_accuracy: 1.0000 - val_loss: 0.1174 - val_categorical_accuracy: 0.9834\n",
      "Epoch 99/100\n",
      " - 1s - loss: 1.9970e-07 - categorical_accuracy: 1.0000 - val_loss: 0.1174 - val_categorical_accuracy: 0.9835\n",
      "Epoch 100/100\n",
      " - 0s - loss: 1.9776e-07 - categorical_accuracy: 1.0000 - val_loss: 0.1176 - val_categorical_accuracy: 0.9832\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x104481f60>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_pca_train, y_train, epochs=100, batch_size=lot_size, validation_split=0.2, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 23us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.10449246602895096, 0.985]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_pca_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import DP optimizers - straight from tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# os.chdir('../../../privacy')\n",
    "# os.getcwd()\n",
    "from privacy import analysis\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from privacy.analysis import privacy_ledger\n",
    "from privacy.analysis.rdp_accountant import compute_rdp_from_ledger\n",
    "from privacy.analysis.rdp_accountant import get_privacy_spent\n",
    "from privacy.optimizers import dp_optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.13.1'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compatibility with tf 1 and 2 APIs\n",
    "try:\n",
    "    GradientDescentOptimizer = tf.train.GradientDescentOptimizer\n",
    "except:  # pylint: disable=bare-except\n",
    "    GradientDescentOptimizer = tf.optimizers.SGD  # pylint: disable=invalid-name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "flags = tf.app.flags\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "flags.DEFINE_boolean('dpsgd', True, 'If True, train with DP-SGD. If False, '\n",
    "                        'train with vanilla SGD.')\n",
    "flags.DEFINE_float('learning_rate', .15, 'Learning rate for training')\n",
    "flags.DEFINE_float('noise_multiplier', 1.1,\n",
    "                      'Ratio of the standard deviation to the clipping norm')\n",
    "flags.DEFINE_float('l2_norm_clip', 1.0, 'Clipping norm')\n",
    "flags.DEFINE_integer('batch_size', 256, 'Batch size')\n",
    "flags.DEFINE_integer('epochs', 60, 'Number of epochs')\n",
    "flags.DEFINE_integer('microbatches', 256, 'Number of microbatches '\n",
    "                        '(must evenly divide batch_size)')\n",
    "flags.DEFINE_string('model_dir', None, 'Model directory')\n",
    "flags.DEFINE_string('f', '', 'kernel')\n",
    "\n",
    "\n",
    "FLAGS = flags.FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FLAGS.noise_multiplier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EpsilonPrintingTrainingHook(tf.train.SessionRunHook):\n",
    "    \n",
    "    \"\"\"Training hook to print current value of epsilon after an epoch.\"\"\"\n",
    "    \n",
    "    def __init__(self, ledger):\n",
    "        \"\"\"Initalizes the EpsilonPrintingTrainingHook.\n",
    "        Args:\n",
    "          ledger: The privacy ledger.\n",
    "        \"\"\"\n",
    "        self._samples, self._queries = ledger.get_unformatted_ledger()\n",
    "\n",
    "    def end(self, session):\n",
    "        orders = [1 + x / 10.0 for x in range(1, 100)] + list(range(12, 64))\n",
    "        samples = session.run(self._samples)\n",
    "        queries = session.run(self._queries)\n",
    "        formatted_ledger = privacy_ledger.format_ledger(samples, queries)\n",
    "        rdp = compute_rdp_from_ledger(formatted_ledger, orders)\n",
    "        eps = get_privacy_spent(orders, rdp, target_delta=1e-5)[0]\n",
    "        print('For delta=1e-5, the current epsilon is: %.2f' % eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model_fn(features, labels, mode):\n",
    "    \"\"\"Model function for a CNN.\"\"\"\n",
    "\n",
    "    # Define CNN architecture using tf.keras.layers.\n",
    "    input_layer = tf.reshape(features['x'], [-1, 28, 28, 1])\n",
    "    y = tf.keras.layers.Conv2D(16, 8,\n",
    "                             strides=2,\n",
    "                             padding='same',\n",
    "                             activation='relu').apply(input_layer)\n",
    "    y = tf.keras.layers.MaxPool2D(2, 1).apply(y)\n",
    "    y = tf.keras.layers.Conv2D(32, 4,\n",
    "                             strides=2,\n",
    "                             padding='valid',\n",
    "                             activation='relu').apply(y)\n",
    "    y = tf.keras.layers.MaxPool2D(2, 1).apply(y)\n",
    "    y = tf.keras.layers.Flatten().apply(y)\n",
    "    y = tf.keras.layers.Dense(32, activation='relu').apply(y)\n",
    "    logits = tf.keras.layers.Dense(10).apply(y)\n",
    "\n",
    "    # Calculate loss as a vector (to support microbatches in DP-SGD).\n",
    "    vector_loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=labels, logits=logits)\n",
    "    # Define mean of loss across minibatch (for reporting through tf.Estimator).\n",
    "    scalar_loss = tf.reduce_mean(vector_loss)\n",
    "\n",
    "    # Configure the training op (for TRAIN mode).\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "\n",
    "        if FLAGS.dpsgd:\n",
    "            ledger = privacy_ledger.PrivacyLedger(\n",
    "              population_size=60000,\n",
    "              selection_probability=(FLAGS.batch_size / 60000),\n",
    "              max_samples=1e6,\n",
    "              max_queries=1e6)\n",
    "\n",
    "      # Use DP version of GradientDescentOptimizer. Other optimizers are\n",
    "      # available in dp_optimizer. Most optimizers inheriting from\n",
    "      # tf.train.Optimizer should be wrappable in differentially private\n",
    "      # counterparts by calling dp_optimizer.optimizer_from_args().\n",
    "            optimizer = dp_optimizer.DPGradientDescentGaussianOptimizer(\n",
    "              l2_norm_clip=FLAGS.l2_norm_clip,\n",
    "              noise_multiplier=FLAGS.noise_multiplier,\n",
    "              num_microbatches=FLAGS.microbatches,\n",
    "              ledger=ledger,\n",
    "              learning_rate=FLAGS.learning_rate)\n",
    "            training_hooks = [\n",
    "              EpsilonPrintingTrainingHook(ledger)\n",
    "            ]\n",
    "            opt_loss = vector_loss\n",
    "        else:\n",
    "            optimizer = GradientDescentOptimizer(learning_rate=FLAGS.learning_rate)\n",
    "            training_hooks = []\n",
    "            opt_loss = scalar_loss\n",
    "            \n",
    "        global_step = tf.train.get_global_step()\n",
    "        train_op = optimizer.minimize(loss=opt_loss, global_step=global_step)\n",
    "        # In the following, we pass the mean of the loss (scalar_loss) rather than\n",
    "        # the vector_loss because tf.estimator requires a scalar loss. This is only\n",
    "        # used for evaluation and debugging by tf.estimator. The actual loss being\n",
    "        # minimized is opt_loss defined above and passed to optimizer.minimize().\n",
    "        return tf.estimator.EstimatorSpec(mode=mode,\n",
    "                                          loss=scalar_loss,\n",
    "                                          train_op=train_op,\n",
    "                                          training_hooks=training_hooks)\n",
    "\n",
    "    # Add evaluation metrics (for EVAL mode).\n",
    "    elif mode == tf.estimator.ModeKeys.EVAL:\n",
    "        eval_metric_ops = {\n",
    "            'accuracy':\n",
    "                tf.metrics.accuracy(\n",
    "                    labels=labels,\n",
    "                    predictions=tf.argmax(input=logits, axis=1))\n",
    "        }\n",
    "\n",
    "    return tf.estimator.EstimatorSpec(mode=mode,\n",
    "                                      loss=scalar_loss,\n",
    "                                      eval_metric_ops=eval_metric_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist():\n",
    "    \"\"\"Loads MNIST and preprocesses to combine training and validation data.\"\"\"\n",
    "    train, test = tf.keras.datasets.mnist.load_data()\n",
    "    train_data, train_labels = train\n",
    "    test_data, test_labels = test\n",
    "\n",
    "    train_data = np.array(train_data, dtype=np.float32) / 255\n",
    "    test_data = np.array(test_data, dtype=np.float32) / 255\n",
    "\n",
    "    train_labels = np.array(train_labels, dtype=np.int32)\n",
    "    test_labels = np.array(test_labels, dtype=np.int32)\n",
    "\n",
    "    assert train_data.min() == 0.\n",
    "    assert train_data.max() == 1.\n",
    "    assert test_data.min() == 0.\n",
    "    assert test_data.max() == 1.\n",
    "    assert train_labels.ndim == 1\n",
    "    assert test_labels.ndim == 1\n",
    "\n",
    "    return train_data, train_labels, test_data, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(flags.FLAGS.dpsgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.13.1'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/y_/1vlns4rd4cz4jg4szvwt_22h0000gn/T/tmprsxhv3xv\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/y_/1vlns4rd4cz4jg4szvwt_22h0000gn/T/tmprsxhv3xv', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x1a2a638860>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "WARNING:tensorflow:From /anaconda3/envs/208proj/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /anaconda3/envs/208proj/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From /Users/lipikaramaswamy/Documents/Harvard/CS208/privacy/privacy/dp_query/gaussian_query.py:49: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /anaconda3/envs/208proj/lib/python3.6/site-packages/tensorflow/python/ops/array_grad.py:425: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/208proj/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Issue encountered when serializing critical_section_executions.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'_ExecutionSignature' object has no attribute 'name'\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "WARNING:tensorflow:From /anaconda3/envs/208proj/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py:809: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:Issue encountered when serializing critical_section_executions.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'_ExecutionSignature' object has no attribute 'name'\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /var/folders/y_/1vlns4rd4cz4jg4szvwt_22h0000gn/T/tmprsxhv3xv/model.ckpt.\n",
      "WARNING:tensorflow:Issue encountered when serializing critical_section_executions.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'_ExecutionSignature' object has no attribute 'name'\n",
      "INFO:tensorflow:loss = 2.3165293, step = 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-eddab42e25c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m# Train the model for one epoch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mmnist_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_input_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m# Evaluate the model and print results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/208proj/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m       \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/208proj/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/208proj/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1156\u001b[0m       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n\u001b[1;32m   1157\u001b[0m                                              \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step_tensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1158\u001b[0;31m                                              saving_listeners)\n\u001b[0m\u001b[1;32m   1159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/208proj/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_with_estimator_spec\u001b[0;34m(self, estimator_spec, worker_hooks, hooks, global_step_tensor, saving_listeners)\u001b[0m\n\u001b[1;32m   1405\u001b[0m       \u001b[0many_step_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1406\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1408\u001b[0m         \u001b[0many_step_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0many_step_done\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/208proj/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    674\u001b[0m                           \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m                           \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m                           run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/208proj/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1169\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1170\u001b[0m                               \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1171\u001b[0;31m                               run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1172\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m         logging.info('An error was raised. This may be due to a preemption in '\n",
      "\u001b[0;32m/anaconda3/envs/208proj/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1253\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1255\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1256\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1257\u001b[0m       \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/208proj/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1325\u001b[0m                                   \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m                                   \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m                                   run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/208proj/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1089\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1091\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1093\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_with_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/208proj/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/208proj/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/208proj/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/208proj/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/208proj/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/208proj/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Create tf.Estimator input functions for the training and test data.\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "  x={'x': train_data},\n",
    "  y=train_labels,\n",
    "  batch_size=FLAGS.batch_size,\n",
    "  num_epochs=FLAGS.epochs,\n",
    "  shuffle=True)\n",
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "  x={'x': test_data},\n",
    "  y=test_labels,\n",
    "  num_epochs=1,\n",
    "  shuffle=False)\n",
    "\n",
    "# Training loop.\n",
    "steps_per_epoch = 60000 // FLAGS.batch_size\n",
    "for epoch in range(1, FLAGS.epochs + 1):\n",
    "    # Train the model for one epoch.\n",
    "    mnist_classifier.train(input_fn=train_input_fn, steps=steps_per_epoch)\n",
    "\n",
    "# Evaluate the model and print results\n",
    "eval_results = mnist_classifier.evaluate(input_fn=eval_input_fn)\n",
    "test_accuracy = eval_results['accuracy']\n",
    "print('Test accuracy after %d epochs is: %.3f' % (epoch, test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
